# ê°€ê²© ìˆ˜ì§‘ ë°°ì¹˜ ì‹œìŠ¤í…œ - í•„í„°ë§ ê°•í™” ë²„ì „

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import time
import json
import sqlite3
from datetime import datetime
import re

class PriceScraper:
    def __init__(self):
        # Chrome ì˜µì…˜ ì„¤ì •
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.db_path = 'prices.db'
        self.init_database()
        
        # ì œì™¸í•  í‚¤ì›Œë“œ (ì•…ì„¸ì„œë¦¬, ë¶€ì†í’ˆ ë“±)
        self.exclude_keywords = [
            'ì¼€ì´ìŠ¤', 'ì»¤ë²„', 'ë³´í˜¸í•„ë¦„', 'í•„ë¦„', 'ì•¡ì •', 'ê±°ì¹˜ëŒ€', 
            'ë°›ì¹¨ëŒ€', 'ìŠ¤íƒ ë“œ', 'ê°€ë°©', 'íŒŒìš°ì¹˜', 'ìŠ¤í‹°ì»¤', 'ë°ì¹¼',
            'ì¶©ì „ê¸°', 'ì–´ëŒ‘í„°', 'ì¼€ì´ë¸”', 'ì„ ', 'ë¦¬ëª¨ì»¨', 'ë¶€í’ˆ',
            'ì•…ì„¸ì‚¬ë¦¬', 'ì•¡ì„¸ì„œë¦¬', 'êµì²´ìš©', 'í˜¸í™˜', 'ëŒ€ì²´',
            'í´ë¦¬ë„ˆ', 'ì²­ì†Œ', 'ì„¸ì²™', 'í•„í„°', 'ë¨¼ì§€', 'ì²­ì†Œê¸°',
            'ìˆ˜ë¦¬', 'ë¶€ì†', 'ì—°ì¥', 'í™•ì¥'
        ]
        
        # ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸
        self.brands = [
            'ì‹ ì¼', 'ì‚¼ì„±', 'LG', 'ì• í”Œ', 'Apple', 'ìƒ¤ì˜¤ë¯¸', 'SK', 'KT',
            'ë‹¤ì´ìŠ¨', 'Dyson', 'ì¿ ì¿ ', 'CUCKOO', 'í•„ë¦½ìŠ¤', 'Philips'
        ]
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS products (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                search_query TEXT NOT NULL,
                shop TEXT NOT NULL,
                name TEXT NOT NULL,
                option_name TEXT,
                original_price INTEGER,
                discount_price INTEGER NOT NULL,
                shipping_fee INTEGER DEFAULT 0,
                final_price INTEGER NOT NULL,
                link TEXT,
                image_url TEXT,
                brand TEXT,
                model_name TEXT,
                search_tokens TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_search_query ON products(search_query)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_shop ON products(shop)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_brand ON products(brand)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_model_name ON products(model_name)
        ''')
        
        conn.commit()
        conn.close()
        print("âœ… Database initialized")
    
    def extract_price(self, price_text):
        """ê°€ê²© í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ"""
        if not price_text:
            return 0
        cleaned = re.sub(r'[^0-9]', '', price_text)
        return int(cleaned) if cleaned else 0
    
    def extract_brand_and_model(self, product_name, search_query):
        """
        ìƒí’ˆëª…ê³¼ ê²€ìƒ‰ì–´ì—ì„œ ë¸Œëœë“œì™€ ëª¨ë¸ëª… ì¶”ì¶œ
        ì˜ˆ: "ì‹ ì¼ íŒ¬íˆí„° SPH-1200" -> brand="ì‹ ì¼", model="SPH-1200"
        """
        brand = None
        model = None
        
        # ë¸Œëœë“œ ì°¾ê¸°
        for b in self.brands:
            if b in product_name or b in search_query:
                brand = b
                break
        
        # ëª¨ë¸ëª… ì¶”ì¶œ: ì˜ë¬¸+ìˆ«ì ì¡°í•© (ì˜ˆ: SPH-1200, iPhone15)
        model_patterns = [
            r'[A-Z]{2,}-?\d{3,}',  # SPH-1200, ABC-123
            r'[A-Z][a-z]+\s?\d+',  # iPhone15, Galaxy23
            r'\d{3,}[A-Z]*',       # 1200W, 2024A
        ]
        
        for pattern in model_patterns:
            match = re.search(pattern, product_name, re.IGNORECASE)
            if match:
                model = match.group(0)
                break
        
        # ëª¨ë¸ëª…ì´ ì—†ìœ¼ë©´ ê²€ìƒ‰ì–´ì—ì„œ ë¸Œëœë“œ ì œì™¸í•œ ë‚˜ë¨¸ì§€
        if not model:
            tokens = search_query.split()
            model_tokens = [t for t in tokens if t != brand and len(t) > 1]
            model = ' '.join(model_tokens) if model_tokens else search_query
        
        return brand, model
    
    def generate_search_tokens(self, product_name, search_query):
        """ê²€ìƒ‰ í† í° ìƒì„± (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ê¸°ì¤€ ë¶„ë¦¬)"""
        tokens = set()
        
        # ìƒí’ˆëª… í† í°í™”
        name_tokens = re.sub(r'[^\w\sê°€-í£]', ' ', product_name.lower()).split()
        tokens.update(name_tokens)
        
        # ê²€ìƒ‰ì–´ í† í°í™”
        query_tokens = re.sub(r'[^\w\sê°€-í£]', ' ', search_query.lower()).split()
        tokens.update(query_tokens)
        
        return '|'.join(tokens)
    
    def is_valid_product(self, name, query):
        """
        ìƒí’ˆëª…ì´ ì‹¤ì œ ë³¸í’ˆì¸ì§€ ê²€ì¦
        - ê²€ìƒ‰ì–´ì˜ í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
        - ì•…ì„¸ì„œë¦¬ í‚¤ì›Œë“œ ì œì™¸
        """
        name_lower = name.lower()
        
        # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
        for keyword in self.exclude_keywords:
            if keyword in name_lower:
                print(f"  âš ï¸ ì œì™¸ë¨ (ì•…ì„¸ì„œë¦¬): {name}")
                return False
        
        # ê²€ìƒ‰ì–´ì˜ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ë¸Œëœë“œ, ëª¨ë¸ëª… ë“±)
        query_keywords = [k.strip() for k in query.split() if len(k.strip()) > 1]
        
        # ìµœì†Œ 2ê°œ ì´ìƒì˜ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ì•¼ í•¨
        matched_count = 0
        for keyword in query_keywords:
            if keyword.lower() in name_lower:
                matched_count += 1
        
        if matched_count < max(2, len(query_keywords) * 0.6):  # 60% ì´ìƒ ë§¤ì¹­
            print(f"  âš ï¸ ì œì™¸ë¨ (ë§¤ì¹­ ë¶€ì¡±): {name}")
            return False
        
        return True
    
    def scrape_naver_shopping(self, query):
        """ë„¤ì´ë²„ ì‡¼í•‘ ê°€ê²© ìˆ˜ì§‘"""
        print(f"ğŸ” ë„¤ì´ë²„ì‡¼í•‘ ê²€ìƒ‰ ì¤‘: {query}")
        products = []
        
        try:
            url = f"https://search.shopping.naver.com/search/all?query={query}"
            self.driver.get(url)
            time.sleep(2)
            
            # ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ê¸°
            items = WebDriverWait(self.driver, 10).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.product_item__MDtDF"))
            )
            
            collected = 0
            for item in items:
                if collected >= 10:  # ìƒìœ„ 10ê°œê¹Œì§€ë§Œ ìˆ˜ì§‘
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.product_title__Mmw2K a").text
                    
                    # ìƒí’ˆëª… ê²€ì¦
                    if not self.is_valid_product(name, query):
                        continue
                    
                    # ê°€ê²© ì •ë³´
                    price_elem = item.find_element(By.CSS_SELECTOR, "span.price_num__S2p_v em")
                    discount_price = self.extract_price(price_elem.text)
                    
                    # ë„ˆë¬´ ì €ë ´í•˜ê±°ë‚˜ ë¹„ì‹¼ ê²½ìš° ì œì™¸ (ì´ìƒì¹˜)
                    if discount_price < 1000 or discount_price > 10000000:
                        print(f"  âš ï¸ ì œì™¸ë¨ (ê°€ê²© ì´ìƒ): {name} ({discount_price}ì›)")
                        continue
                    
                    # ë°°ì†¡ë¹„
                    try:
                        shipping_elem = item.find_element(By.CSS_SELECTOR, "span.product_delivery__RclQf")
                        shipping = 0 if "ë¬´ë£Œ" in shipping_elem.text else 2500
                    except:
                        shipping = 2500
                    
                    # ë§í¬
                    link = item.find_element(By.CSS_SELECTOR, "a.product_link__TrAac").get_attribute("href")
                    
                    # ì´ë¯¸ì§€
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'ë„¤ì´ë²„ì‡¼í•‘',
                        'name': name,
                        'option': 'ë‹¨ì¼',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  âœ… ìˆ˜ì§‘: {name[:50]}... ({discount_price:,}ì›)")
                    
                except Exception as e:
                    continue
            
            print(f"  âœ… ì´ {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            
        except Exception as e:
            print(f"  âŒ ë„¤ì´ë²„ì‡¼í•‘ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        
        return products
    
    def scrape_coupang(self, query):
        """ì¿ íŒ¡ ê°€ê²© ìˆ˜ì§‘"""
        print(f"ğŸ” ì¿ íŒ¡ ê²€ìƒ‰ ì¤‘: {query}")
        products = []
        
        try:
            url = f"https://www.coupang.com/np/search?q={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "li.search-product")
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.name").text
                    
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "strong.price-value")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    # ë¡œì¼“ë°°ì†¡ í™•ì¸
                    try:
                        item.find_element(By.CSS_SELECTOR, "span.badge.rocket")
                        shipping = 0
                    except:
                        shipping = 2500
                    
                    link_elem = item.find_element(By.CSS_SELECTOR, "a.search-product-link")
                    link = "https://www.coupang.com" + link_elem.get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img.search-product-wrap-img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'ì¿ íŒ¡',
                        'name': name,
                        'option': 'ë‹¨ì¼',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  âœ… ìˆ˜ì§‘: {name[:50]}... ({discount_price:,}ì›)")
                    
                except Exception as e:
                    continue
            
            print(f"  âœ… ì´ {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            
        except Exception as e:
            print(f"  âŒ ì¿ íŒ¡ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        
        return products
    
    def scrape_gmarket(self, query):
        """Gë§ˆì¼“ ê°€ê²© ìˆ˜ì§‘"""
        print(f"ğŸ” Gë§ˆì¼“ ê²€ìƒ‰ ì¤‘: {query}")
        products = []
        
        try:
            url = f"https://browse.gmarket.co.kr/search?keyword={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "div.box__item-container")
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "span.text__item").text
                    
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "strong.text__value")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    shipping = 2500
                    
                    link = item.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'Gë§ˆì¼“',
                        'name': name,
                        'option': 'ë‹¨ì¼',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  âœ… ìˆ˜ì§‘: {name[:50]}... ({discount_price:,}ì›)")
                    
                except Exception as e:
                    continue
            
            print(f"  âœ… ì´ {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            
        except Exception as e:
            print(f"  âŒ Gë§ˆì¼“ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        
        return products
    
    def save_to_db(self, query, products):
        """ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ê°™ì€ ê²€ìƒ‰ì–´)
        cursor.execute("DELETE FROM products WHERE search_query = ?", (query,))
        
        # ìƒˆ ë°ì´í„° ì €ì¥
        for product in products:
            # ë¸Œëœë“œ/ëª¨ë¸ëª… ì¶”ì¶œ
            brand, model = self.extract_brand_and_model(product['name'], query)
            search_tokens = self.generate_search_tokens(product['name'], query)
            
            cursor.execute('''
                INSERT INTO products 
                (search_query, shop, name, option_name, original_price, 
                 discount_price, shipping_fee, final_price, link, image_url,
                 brand, model_name, search_tokens)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                query,
                product['shop'],
                product['name'],
                product['option'],
                product['originalPrice'],
                product['discountPrice'],
                product['shipping'],
                product['finalPrice'],
                product['link'],
                product.get('image', ''),
                brand,
                model,
                search_tokens
            ))
        
        conn.commit()
        conn.close()
        print(f"ğŸ’¾ DBì— {len(products)}ê°œ ìƒí’ˆ ì €ì¥ ì™„ë£Œ")
    
    def export_to_json(self, query):
        """DB ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT shop, name, option_name, original_price, discount_price, 
                   shipping_fee, final_price, link, image_url, updated_at
            FROM products 
            WHERE search_query = ?
            ORDER BY final_price ASC
        ''', (query,))
        
        rows = cursor.fetchall()
        conn.close()
        
        products = []
        for row in rows:
            products.append({
                'shop': row[0],
                'name': row[1],
                'option': row[2],
                'originalPrice': row[3],
                'discountPrice': row[4],
                'shipping': row[5],
                'finalPrice': row[6],
                'link': row[7],
                'image': row[8],
                'updatedAt': row[9]
            })
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        filename = f"data_{query.replace(' ', '_')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'query': query,
                'count': len(products),
                'updatedAt': datetime.now().isoformat(),
                'products': products
            }, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ {filename} ìƒì„± ì™„ë£Œ")
        return filename
    
    def run_batch(self, queries):
        """ë°°ì¹˜ ì‹¤í–‰"""
        print("=" * 50)
        print("ğŸš€ ê°€ê²© ìˆ˜ì§‘ ë°°ì¹˜ ì‹œì‘ (í•„í„°ë§ ê°•í™”)")
        print("=" * 50)
        print()
        
        for query in queries:
            print(f"\n{'='*50}")
            print(f"ê²€ìƒ‰ì–´: {query}")
            print('='*50)
            
            all_products = []
            
            # ê° ì‡¼í•‘ëª°ì—ì„œ ìˆ˜ì§‘
            all_products.extend(self.scrape_naver_shopping(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_coupang(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_gmarket(query))
            time.sleep(1)
            
            # ì¤‘ë³µ ì œê±° (ê°™ì€ ì´ë¦„ì˜ ìƒí’ˆ)
            unique_products = []
            seen_names = set()
            for product in all_products:
                name_key = product['name'].lower()[:50]  # ì²« 50ìë¡œ ë¹„êµ
                if name_key not in seen_names:
                    unique_products.append(product)
                    seen_names.add(name_key)
            
            print(f"\nğŸ“Š ì¤‘ë³µ ì œê±°: {len(all_products)}ê°œ â†’ {len(unique_products)}ê°œ")
            
            # DB ì €ì¥
            if unique_products:
                self.save_to_db(query, unique_products)
                self.export_to_json(query)
            else:
                print("âš ï¸ ìˆ˜ì§‘ëœ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤")
            
            print()
        
        print("=" * 50)
        print("âœ… ë°°ì¹˜ ì™„ë£Œ")
        print("=" * 50)
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.driver.quit()


if __name__ == "__main__":
    # ìˆ˜ì§‘í•  ê²€ìƒ‰ì–´ ëª©ë¡
    search_queries = [
        "ì‹ ì¼ íŒ¬íˆí„° 1200",
        "ë‹¤ì´ìŠ¨ ì²­ì†Œê¸° V11",
        "ì‚¼ì„± ê°¤ëŸ­ì‹œ ë²„ì¦ˆ2"
    ]
    
    scraper = PriceScraper()
    
    try:
        scraper.run_batch(search_queries)
    finally:
        scraper.close()

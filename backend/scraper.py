# ê°€ê²© ìˆ˜ì§‘ ë°°ì¹˜ ì‹œìŠ¤í…œ

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import time
import json
import sqlite3
from datetime import datetime
import re

class PriceScraper:
    def __init__(self):
        # Chrome ì˜µì…˜ ì„¤ì •
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.db_path = 'prices.db'
        self.init_database()
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS products (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                search_query TEXT NOT NULL,
                shop TEXT NOT NULL,
                name TEXT NOT NULL,
                option_name TEXT,
                original_price INTEGER,
                discount_price INTEGER NOT NULL,
                shipping_fee INTEGER DEFAULT 0,
                final_price INTEGER NOT NULL,
                link TEXT,
                image_url TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_search_query ON products(search_query)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_shop ON products(shop)
        ''')
        
        conn.commit()
        conn.close()
        print("âœ… Database initialized")
    
    def extract_price(self, price_text):
        """ê°€ê²© í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ"""
        if not price_text:
            return 0
        cleaned = re.sub(r'[^0-9]', '', price_text)
        return int(cleaned) if cleaned else 0
    
    def scrape_naver_shopping(self, query):
        """ë„¤ì´ë²„ ì‡¼í•‘ ê°€ê²© ìˆ˜ì§‘"""
        print(f"ğŸ” ë„¤ì´ë²„ì‡¼í•‘ ê²€ìƒ‰ ì¤‘: {query}")
        products = []
        
        try:
            url = f"https://search.shopping.naver.com/search/all?query={query}"
            self.driver.get(url)
            time.sleep(2)
            
            # ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ê¸°
            items = WebDriverWait(self.driver, 10).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.product_item__MDtDF"))
            )
            
            for item in items[:5]:  # ìƒìœ„ 5ê°œë§Œ
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.product_title__Mmw2K a").text
                    
                    # ê°€ê²© ì •ë³´
                    price_elem = item.find_element(By.CSS_SELECTOR, "span.price_num__S2p_v em")
                    discount_price = self.extract_price(price_elem.text)
                    
                    # ë°°ì†¡ë¹„
                    try:
                        shipping_elem = item.find_element(By.CSS_SELECTOR, "span.product_delivery__RclQf")
                        shipping = 0 if "ë¬´ë£Œ" in shipping_elem.text else 2500
                    except:
                        shipping = 2500
                    
                    # ë§í¬
                    link = item.find_element(By.CSS_SELECTOR, "a.product_link__TrAac").get_attribute("href")
                    
                    # ì´ë¯¸ì§€
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'ë„¤ì´ë²„ì‡¼í•‘',
                        'name': name,
                        'option': 'ë‹¨ì¼',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    
                except Exception as e:
                    print(f"  âš ï¸ ìƒí’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
            
            print(f"  âœ… {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            
        except Exception as e:
            print(f"  âŒ ë„¤ì´ë²„ì‡¼í•‘ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        
        return products
    
    def scrape_coupang(self, query):
        """ì¿ íŒ¡ ê°€ê²© ìˆ˜ì§‘"""
        print(f"ğŸ” ì¿ íŒ¡ ê²€ìƒ‰ ì¤‘: {query}")
        products = []
        
        try:
            url = f"https://www.coupang.com/np/search?q={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "li.search-product")
            
            for item in items[:5]:
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.name").text
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "strong.price-value")
                    discount_price = self.extract_price(price_elem.text)
                    
                    # ë¡œì¼“ë°°ì†¡ í™•ì¸
                    try:
                        item.find_element(By.CSS_SELECTOR, "span.badge.rocket")
                        shipping = 0
                    except:
                        shipping = 2500
                    
                    link_elem = item.find_element(By.CSS_SELECTOR, "a.search-product-link")
                    link = "https://www.coupang.com" + link_elem.get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img.search-product-wrap-img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'ì¿ íŒ¡',
                        'name': name,
                        'option': 'ë‹¨ì¼',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    
                except Exception as e:
                    continue
            
            print(f"  âœ… {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            
        except Exception as e:
            print(f"  âŒ ì¿ íŒ¡ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        
        return products
    
    def scrape_gmarket(self, query):
        """Gë§ˆì¼“ ê°€ê²© ìˆ˜ì§‘"""
        print(f"ğŸ” Gë§ˆì¼“ ê²€ìƒ‰ ì¤‘: {query}")
        products = []
        
        try:
            url = f"https://browse.gmarket.co.kr/search?keyword={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "div.box__item-container")
            
            for item in items[:5]:
                try:
                    name = item.find_element(By.CSS_SELECTOR, "span.text__item").text
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "strong.text__value")
                    discount_price = self.extract_price(price_elem.text)
                    
                    shipping = 2500
                    
                    link = item.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'Gë§ˆì¼“',
                        'name': name,
                        'option': 'ë‹¨ì¼',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    
                except Exception as e:
                    continue
            
            print(f"  âœ… {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            
        except Exception as e:
            print(f"  âŒ Gë§ˆì¼“ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        
        return products
    
    def save_to_db(self, query, products):
        """ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ê°™ì€ ê²€ìƒ‰ì–´)
        cursor.execute("DELETE FROM products WHERE search_query = ?", (query,))
        
        # ìƒˆ ë°ì´í„° ì €ì¥
        for product in products:
            cursor.execute('''
                INSERT INTO products 
                (search_query, shop, name, option_name, original_price, 
                 discount_price, shipping_fee, final_price, link, image_url)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                query,
                product['shop'],
                product['name'],
                product['option'],
                product['originalPrice'],
                product['discountPrice'],
                product['shipping'],
                product['finalPrice'],
                product['link'],
                product.get('image', '')
            ))
        
        conn.commit()
        conn.close()
        print(f"ğŸ’¾ DBì— {len(products)}ê°œ ìƒí’ˆ ì €ì¥ ì™„ë£Œ")
    
    def export_to_json(self, query):
        """DB ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT shop, name, option_name, original_price, discount_price, 
                   shipping_fee, final_price, link, image_url, updated_at
            FROM products 
            WHERE search_query = ?
            ORDER BY final_price ASC
        ''', (query,))
        
        rows = cursor.fetchall()
        conn.close()
        
        products = []
        for row in rows:
            products.append({
                'shop': row[0],
                'name': row[1],
                'option': row[2],
                'originalPrice': row[3],
                'discountPrice': row[4],
                'shipping': row[5],
                'finalPrice': row[6],
                'link': row[7],
                'image': row[8],
                'updatedAt': row[9]
            })
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        filename = f"data_{query.replace(' ', '_')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'query': query,
                'count': len(products),
                'updatedAt': datetime.now().isoformat(),
                'products': products
            }, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ {filename} ìƒì„± ì™„ë£Œ")
        return filename
    
    def run_batch(self, queries):
        """ë°°ì¹˜ ì‹¤í–‰"""
        print("=" * 50)
        print("ğŸš€ ê°€ê²© ìˆ˜ì§‘ ë°°ì¹˜ ì‹œì‘")
        print("=" * 50)
        print()
        
        for query in queries:
            print(f"\n{'='*50}")
            print(f"ê²€ìƒ‰ì–´: {query}")
            print('='*50)
            
            all_products = []
            
            # ê° ì‡¼í•‘ëª°ì—ì„œ ìˆ˜ì§‘
            all_products.extend(self.scrape_naver_shopping(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_coupang(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_gmarket(query))
            time.sleep(1)
            
            # DB ì €ì¥
            if all_products:
                self.save_to_db(query, all_products)
                self.export_to_json(query)
            else:
                print("âš ï¸ ìˆ˜ì§‘ëœ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤")
            
            print()
        
        print("=" * 50)
        print("âœ… ë°°ì¹˜ ì™„ë£Œ")
        print("=" * 50)
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.driver.quit()


if __name__ == "__main__":
    # ìˆ˜ì§‘í•  ê²€ìƒ‰ì–´ ëª©ë¡
    search_queries = [
        "ì‹ ì¼ íŒ¬íˆí„° 1200",
        "ë‹¤ì´ìŠ¨ ì²­ì†Œê¸°",
        "ì‚¼ì„± ê°¤ëŸ­ì‹œ ë²„ì¦ˆ"
    ]
    
    scraper = PriceScraper()
    
    try:
        scraper.run_batch(search_queries)
    finally:
        scraper.close()

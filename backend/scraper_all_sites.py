# Ï†ÑÏ≤¥ Ïò®ÎùºÏù∏ ÏáºÌïëÎ™∞ Í∞ÄÍ≤© ÏàòÏßë ÏãúÏä§ÌÖú

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import time
import json
import sqlite3
from datetime import datetime
import re

class PriceScraperAllSites:
    def __init__(self):
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.db_path = 'prices.db'
        self.init_database()
        
        # Ï†úÏô∏ ÌÇ§ÏõåÎìú
        self.exclude_keywords = [
            'ÏºÄÏù¥Ïä§', 'Ïª§Î≤Ñ', 'Î≥¥Ìò∏ÌïÑÎ¶Ñ', 'ÌïÑÎ¶Ñ', 'Ïï°Ï†ï', 'Í±∞ÏπòÎåÄ', 
            'Î∞õÏπ®ÎåÄ', 'Ïä§ÌÉ†Îìú', 'Í∞ÄÎ∞©', 'ÌååÏö∞Ïπò', 'Ïä§Ìã∞Ïª§', 'Îç∞Ïπº',
            'Ï∂©Ï†ÑÍ∏∞', 'Ïñ¥ÎåëÌÑ∞', 'ÏºÄÏù¥Î∏î', 'ÏÑ†', 'Î¶¨Î™®Ïª®', 'Î∂ÄÌíà',
            'ÏïÖÏÑ∏ÏÇ¨Î¶¨', 'Ïï°ÏÑ∏ÏÑúÎ¶¨', 'ÍµêÏ≤¥Ïö©', 'Ìò∏Ìôò', 'ÎåÄÏ≤¥',
            'ÌÅ¥Î¶¨ÎÑà', 'Ï≤≠ÏÜå', 'ÏÑ∏Ï≤ô', 'ÌïÑÌÑ∞', 'Î®ºÏßÄ', 'Ï≤≠ÏÜåÍ∏∞',
            'ÏàòÎ¶¨', 'Î∂ÄÏÜç', 'Ïó∞Ïû•', 'ÌôïÏû•'
        ]
        
        # Î∏åÎûúÎìú Î¶¨Ïä§Ìä∏
        self.brands = [
            'Ïã†Ïùº', 'ÏÇºÏÑ±', 'LG', 'Ïï†Ìîå', 'Apple', 'ÏÉ§Ïò§ÎØ∏', 'SK', 'KT',
            'Îã§Ïù¥Ïä®', 'Dyson', 'Ïø†Ïø†', 'CUCKOO', 'ÌïÑÎ¶ΩÏä§', 'Philips'
        ]
    
    def init_database(self):
        """Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï¥àÍ∏∞Ìôî"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS products (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                search_query TEXT NOT NULL,
                shop TEXT NOT NULL,
                name TEXT NOT NULL,
                option_name TEXT,
                original_price INTEGER,
                discount_price INTEGER NOT NULL,
                shipping_fee INTEGER DEFAULT 0,
                final_price INTEGER NOT NULL,
                link TEXT,
                image_url TEXT,
                brand TEXT,
                model_name TEXT,
                search_tokens TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_search_query ON products(search_query)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_shop ON products(shop)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_brand ON products(brand)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_model_name ON products(model_name)')
        
        conn.commit()
        conn.close()
        print("‚úÖ Database initialized")
    
    def extract_price(self, price_text):
        """Í∞ÄÍ≤© ÌÖçÏä§Ìä∏ÏóêÏÑú Ïà´ÏûêÎßå Ï∂îÏ∂ú"""
        if not price_text:
            return 0
        cleaned = re.sub(r'[^0-9]', '', price_text)
        return int(cleaned) if cleaned else 0
    
    def extract_brand_and_model(self, product_name, search_query):
        """Î∏åÎûúÎìúÏôÄ Î™®Îç∏Î™Ö Ï∂îÏ∂ú"""
        brand = None
        model = None
        
        for b in self.brands:
            if b in product_name or b in search_query:
                brand = b
                break
        
        model_patterns = [
            r'[A-Z]{2,}-?\d{3,}',
            r'[A-Z][a-z]+\s?\d+',
            r'\d{3,}[A-Z]*',
        ]
        
        for pattern in model_patterns:
            match = re.search(pattern, product_name, re.IGNORECASE)
            if match:
                model = match.group(0)
                break
        
        if not model:
            tokens = search_query.split()
            model_tokens = [t for t in tokens if t != brand and len(t) > 1]
            model = ' '.join(model_tokens) if model_tokens else search_query
        
        return brand, model
    
    def generate_search_tokens(self, product_name, search_query):
        """Í≤ÄÏÉâ ÌÜ†ÌÅ∞ ÏÉùÏÑ±"""
        tokens = set()
        name_tokens = re.sub(r'[^\w\sÍ∞Ä-Ìû£]', ' ', product_name.lower()).split()
        tokens.update(name_tokens)
        query_tokens = re.sub(r'[^\w\sÍ∞Ä-Ìû£]', ' ', search_query.lower()).split()
        tokens.update(query_tokens)
        return '|'.join(tokens)
    
    def is_valid_product(self, name, query):
        """ÏÉÅÌíàÎ™Ö Í≤ÄÏ¶ù"""
        name_lower = name.lower()
        
        for keyword in self.exclude_keywords:
            if keyword in name_lower:
                print(f"  ‚ö†Ô∏è Ï†úÏô∏Îê® (ÏïÖÏÑ∏ÏÑúÎ¶¨): {name}")
                return False
        
        query_keywords = [k.strip() for k in query.split() if len(k.strip()) > 1]
        matched_count = sum(1 for keyword in query_keywords if keyword.lower() in name_lower)
        
        if matched_count < max(2, len(query_keywords) * 0.6):
            print(f"  ‚ö†Ô∏è Ï†úÏô∏Îê® (Îß§Ïπ≠ Î∂ÄÏ°±): {name}")
            return False
        
        return True
    
    def scrape_naver_shopping(self, query):
        """ÎÑ§Ïù¥Î≤ÑÏáºÌïë ÏàòÏßë"""
        print(f"üîç ÎÑ§Ïù¥Î≤ÑÏáºÌïë Í≤ÄÏÉâ: {query}")
        products = []
        
        try:
            url = f"https://search.shopping.naver.com/search/all?query={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = WebDriverWait(self.driver, 10).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.product_item__MDtDF"))
            )
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.product_title__Mmw2K a").text
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "span.price_num__S2p_v em")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    try:
                        shipping_elem = item.find_element(By.CSS_SELECTOR, "span.product_delivery__RclQf")
                        shipping = 0 if "Î¨¥Î£å" in shipping_elem.text else 2500
                    except:
                        shipping = 2500
                    
                    link = item.find_element(By.CSS_SELECTOR, "a.product_link__TrAac").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'ÎÑ§Ïù¥Î≤ÑÏáºÌïë',
                        'name': name,
                        'option': 'Îã®Ïùº',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  ‚úÖ ÏàòÏßë: {name[:50]}... ({discount_price:,}Ïõê)")
                    
                except Exception as e:
                    continue
            
            print(f"  ‚úÖ ÎÑ§Ïù¥Î≤ÑÏáºÌïë {len(products)}Í∞ú ÏàòÏßë")
        except Exception as e:
            print(f"  ‚ùå ÎÑ§Ïù¥Î≤ÑÏáºÌïë Ïã§Ìå®: {e}")
        
        return products
    
    def scrape_coupang(self, query):
        """Ïø†Ìå° ÏàòÏßë"""
        print(f"üîç Ïø†Ìå° Í≤ÄÏÉâ: {query}")
        products = []
        
        try:
            url = f"https://www.coupang.com/np/search?q={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "li.search-product")
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.name").text
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "strong.price-value")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    try:
                        shipping_elem = item.find_element(By.CSS_SELECTOR, "span.shipping")
                        shipping = 0 if "Î¨¥Î£å" in shipping_elem.text else 2500
                    except:
                        shipping = 0
                    
                    link = item.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'Ïø†Ìå°',
                        'name': name,
                        'option': 'Îã®Ïùº',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  ‚úÖ ÏàòÏßë: {name[:50]}... ({discount_price:,}Ïõê)")
                    
                except Exception as e:
                    continue
            
            print(f"  ‚úÖ Ïø†Ìå° {len(products)}Í∞ú ÏàòÏßë")
        except Exception as e:
            print(f"  ‚ùå Ïø†Ìå° Ïã§Ìå®: {e}")
        
        return products
    
    def scrape_gmarket(self, query):
        """GÎßàÏºì ÏàòÏßë"""
        print(f"üîç GÎßàÏºì Í≤ÄÏÉâ: {query}")
        products = []
        
        try:
            url = f"https://browse.gmarket.co.kr/search?keyword={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "div.box__item-container")
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "span.text__item").text
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "strong.text__value")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    shipping = 2500
                    link = item.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'GÎßàÏºì',
                        'name': name,
                        'option': 'Îã®Ïùº',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  ‚úÖ ÏàòÏßë: {name[:50]}... ({discount_price:,}Ïõê)")
                    
                except Exception as e:
                    continue
            
            print(f"  ‚úÖ GÎßàÏºì {len(products)}Í∞ú ÏàòÏßë")
        except Exception as e:
            print(f"  ‚ùå GÎßàÏºì Ïã§Ìå®: {e}")
        
        return products
    
    def scrape_11st(self, query):
        """11Î≤àÍ∞Ä ÏàòÏßë"""
        print(f"üîç 11Î≤àÍ∞Ä Í≤ÄÏÉâ: {query}")
        products = []
        
        try:
            url = f"https://search.11st.co.kr/Search.tmall?kwd={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "div.c_prd_item")
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.c_prd_name a").text
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "span.c_prd_price em")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    shipping = 2500
                    link = item.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': '11Î≤àÍ∞Ä',
                        'name': name,
                        'option': 'Îã®Ïùº',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  ‚úÖ ÏàòÏßë: {name[:50]}... ({discount_price:,}Ïõê)")
                    
                except Exception as e:
                    continue
            
            print(f"  ‚úÖ 11Î≤àÍ∞Ä {len(products)}Í∞ú ÏàòÏßë")
        except Exception as e:
            print(f"  ‚ùå 11Î≤àÍ∞Ä Ïã§Ìå®: {e}")
        
        return products
    
    def scrape_auction(self, query):
        """Ïò•ÏÖò ÏàòÏßë"""
        print(f"üîç Ïò•ÏÖò Í≤ÄÏÉâ: {query}")
        products = []
        
        try:
            url = f"https://browse.auction.co.kr/search?keyword={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "div.box__item-container")
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "span.text__item").text
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "strong.text__value")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    shipping = 2500
                    link = item.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'Ïò•ÏÖò',
                        'name': name,
                        'option': 'Îã®Ïùº',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  ‚úÖ ÏàòÏßë: {name[:50]}... ({discount_price:,}Ïõê)")
                    
                except Exception as e:
                    continue
            
            print(f"  ‚úÖ Ïò•ÏÖò {len(products)}Í∞ú ÏàòÏßë")
        except Exception as e:
            print(f"  ‚ùå Ïò•ÏÖò Ïã§Ìå®: {e}")
        
        return products
    
    def scrape_ssg(self, query):
        """SSGÎã∑Ïª¥ ÏàòÏßë"""
        print(f"üîç SSGÎã∑Ïª¥ Í≤ÄÏÉâ: {query}")
        products = []
        
        try:
            url = f"https://www.ssg.com/search.ssg?target=all&query={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "div.cunit_prod")
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.cunit_title a").text
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "em.ssg_price")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    shipping = 2500
                    link = item.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'SSGÎã∑Ïª¥',
                        'name': name,
                        'option': 'Îã®Ïùº',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  ‚úÖ ÏàòÏßë: {name[:50]}... ({discount_price:,}Ïõê)")
                    
                except Exception as e:
                    continue
            
            print(f"  ‚úÖ SSGÎã∑Ïª¥ {len(products)}Í∞ú ÏàòÏßë")
        except Exception as e:
            print(f"  ‚ùå SSGÎã∑Ïª¥ Ïã§Ìå®: {e}")
        
        return products
    
    def scrape_lotte(self, query):
        """Î°ØÎç∞Ïò® ÏàòÏßë"""
        print(f"üîç Î°ØÎç∞Ïò® Í≤ÄÏÉâ: {query}")
        products = []
        
        try:
            url = f"https://www.lotteon.com/search/search/search.ecn?render=search&platform=pc&q={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "div.srchProductUnitWrap")
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.srchProductName a").text
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "em.srchProductPrice")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    shipping = 2500
                    link = item.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'Î°ØÎç∞Ïò®',
                        'name': name,
                        'option': 'Îã®Ïùº',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  ‚úÖ ÏàòÏßë: {name[:50]}... ({discount_price:,}Ïõê)")
                    
                except Exception as e:
                    continue
            
            print(f"  ‚úÖ Î°ØÎç∞Ïò® {len(products)}Í∞ú ÏàòÏßë")
        except Exception as e:
            print(f"  ‚ùå Î°ØÎç∞Ïò® Ïã§Ìå®: {e}")
        
        return products
    
    def scrape_interpark(self, query):
        """Ïù∏ÌÑ∞ÌååÌÅ¨ ÏàòÏßë"""
        print(f"üîç Ïù∏ÌÑ∞ÌååÌÅ¨ Í≤ÄÏÉâ: {query}")
        products = []
        
        try:
            url = f"https://shopping.interpark.com/search?q={query}"
            self.driver.get(url)
            time.sleep(2)
            
            items = self.driver.find_elements(By.CSS_SELECTOR, "li.productList__item")
            
            collected = 0
            for item in items:
                if collected >= 10:
                    break
                    
                try:
                    name = item.find_element(By.CSS_SELECTOR, "div.productList__name").text
                    if not self.is_valid_product(name, query):
                        continue
                    
                    price_elem = item.find_element(By.CSS_SELECTOR, "span.productList__price")
                    discount_price = self.extract_price(price_elem.text)
                    
                    if discount_price < 1000 or discount_price > 10000000:
                        continue
                    
                    shipping = 2500
                    link = item.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                    
                    try:
                        img = item.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                    except:
                        img = ""
                    
                    products.append({
                        'shop': 'Ïù∏ÌÑ∞ÌååÌÅ¨',
                        'name': name,
                        'option': 'Îã®Ïùº',
                        'originalPrice': discount_price,
                        'discountPrice': discount_price,
                        'shipping': shipping,
                        'finalPrice': discount_price + shipping,
                        'link': link,
                        'image': img
                    })
                    collected += 1
                    print(f"  ‚úÖ ÏàòÏßë: {name[:50]}... ({discount_price:,}Ïõê)")
                    
                except Exception as e:
                    continue
            
            print(f"  ‚úÖ Ïù∏ÌÑ∞ÌååÌÅ¨ {len(products)}Í∞ú ÏàòÏßë")
        except Exception as e:
            print(f"  ‚ùå Ïù∏ÌÑ∞ÌååÌÅ¨ Ïã§Ìå®: {e}")
        
        return products
    
    def save_to_db(self, query, products):
        """DB Ï†ÄÏû•"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("DELETE FROM products WHERE search_query = ?", (query,))
        
        for product in products:
            brand, model = self.extract_brand_and_model(product['name'], query)
            search_tokens = self.generate_search_tokens(product['name'], query)
            
            cursor.execute('''
                INSERT INTO products 
                (search_query, shop, name, option_name, original_price, 
                 discount_price, shipping_fee, final_price, link, image_url,
                 brand, model_name, search_tokens)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                query, product['shop'], product['name'], product['option'],
                product['originalPrice'], product['discountPrice'],
                product['shipping'], product['finalPrice'],
                product['link'], product.get('image', ''),
                brand, model, search_tokens
            ))
        
        conn.commit()
        conn.close()
        print(f"üíæ DBÏóê {len(products)}Í∞ú Ï†ÄÏû•")
    
    def export_to_json(self, query):
        """JSON ÎÇ¥Î≥¥ÎÇ¥Í∏∞"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT shop, name, option_name, original_price, discount_price, 
                   shipping_fee, final_price, link, image_url, updated_at
            FROM products 
            WHERE search_query = ?
            ORDER BY final_price ASC
        ''', (query,))
        
        rows = cursor.fetchall()
        conn.close()
        
        products = []
        for row in rows:
            products.append({
                'shop': row[0], 'name': row[1], 'option': row[2],
                'originalPrice': row[3], 'discountPrice': row[4],
                'shipping': row[5], 'finalPrice': row[6],
                'link': row[7], 'image': row[8], 'updatedAt': row[9]
            })
        
        filename = f"data_{query.replace(' ', '_')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'query': query,
                'count': len(products),
                'updatedAt': datetime.now().isoformat(),
                'products': products
            }, f, ensure_ascii=False, indent=2)
        
        print(f"üìÑ {filename} ÏÉùÏÑ±")
        return filename
    
    def run_batch(self, queries):
        """Î∞∞Ïπò Ïã§Ìñâ - Î™®Îì† ÏáºÌïëÎ™∞ ÏàòÏßë"""
        print("="*60)
        print("üöÄ Ï†ÑÏ≤¥ Ïò®ÎùºÏù∏ ÏáºÌïëÎ™∞ Í∞ÄÍ≤© ÏàòÏßë ÏãúÏûë")
        print("üìç ÏàòÏßë ÎåÄÏÉÅ: ÎÑ§Ïù¥Î≤ÑÏáºÌïë, Ïø†Ìå°, GÎßàÏºì, 11Î≤àÍ∞Ä, Ïò•ÏÖò, SSG, Î°ØÎç∞Ïò®, Ïù∏ÌÑ∞ÌååÌÅ¨")
        print("="*60)
        
        for query in queries:
            print(f"\n{'='*60}")
            print(f"üîç Í≤ÄÏÉâÏñ¥: {query}")
            print('='*60)
            
            all_products = []
            
            # Î™®Îì† ÏáºÌïëÎ™∞ ÏàòÏßë
            all_products.extend(self.scrape_naver_shopping(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_coupang(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_gmarket(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_11st(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_auction(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_ssg(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_lotte(query))
            time.sleep(1)
            
            all_products.extend(self.scrape_interpark(query))
            time.sleep(1)
            
            # Ï§ëÎ≥µ Ï†úÍ±∞
            unique_products = []
            seen_names = set()
            for product in all_products:
                name_key = product['name'].lower()[:50]
                if name_key not in seen_names:
                    unique_products.append(product)
                    seen_names.add(name_key)
            
            print(f"\nüìä ÏàòÏßë Í≤∞Í≥º: {len(all_products)}Í∞ú ‚Üí Ï§ëÎ≥µÏ†úÍ±∞ ÌõÑ {len(unique_products)}Í∞ú")
            
            if unique_products:
                self.save_to_db(query, unique_products)
                self.export_to_json(query)
            else:
                print("‚ö†Ô∏è ÏàòÏßëÎêú ÏÉÅÌíà ÏóÜÏùå")
        
        print("\n" + "="*60)
        print("‚úÖ Ï†ÑÏ≤¥ ÏáºÌïëÎ™∞ ÏàòÏßë ÏôÑÎ£å")
        print("="*60)
    
    def close(self):
        """Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨"""
        self.driver.quit()


if __name__ == "__main__":
    search_queries = [
        "Ïã†Ïùº Ìå¨ÌûàÌÑ∞ 1200",
        "Îã§Ïù¥Ïä® Ï≤≠ÏÜåÍ∏∞ V11",
        "ÏÇºÏÑ± Í∞§Îü≠Ïãú Î≤ÑÏ¶à2"
    ]
    
    scraper = PriceScraperAllSites()
    
    try:
        scraper.run_batch(search_queries)
    finally:
        scraper.close()
